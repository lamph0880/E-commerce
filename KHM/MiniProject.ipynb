{
   "cells": [
      {
         "cell_type": "markdown",
         "id": "d92075e8",
         "metadata": {},
         "source": [
            "## 📦 [데이터셋] 전자상거래 배송 데이터 (Customer Analytics)\n",
            "\n",
            "본 데이터셋은 국제 전자상거래 업체의 고객 데이터로, **제품 배송의 정시 도착 여부**를 분석하고 예측하기 위한 목적으로 구성되었습니다.\n",
            "\n",
            "### 1. 타겟 변수 (Target Variable)\n",
            "* **Reached.on.Time_Y.N**: 제품의 정시 도착 여부\n",
            "    * **1**: 지연 도착 (Delayed)\n",
            "    * **0**: 정시 도착 (On Time)\n",
            "\n",
            "---\n",
            "\n",
            "### 2. 데이터 컬럼 상세 설명 (Features)\n",
            "\n",
            "| 컬럼명 | 설명 | 데이터 타입 | 비고 (Perspective) |\n",
            "| :--- | :--- | :--- | :--- |\n",
            "| **ID** | 고객 고유 식별 번호 | Integer | 예측 모델 구축 시 제거 대상 |\n",
            "| **Warehouse_block** | 창고 구역 (A, B, C, D, E) | Object | 구역별 물류 부하 및 병목 현상 확인 |\n",
            "| **Mode_of_Shipment** | 배송 수단 (Ship, Flight, Road) | Object | 수단별 지연율(지연 비중) 분석의 핵심 |\n",
            "| **Customer_care_calls** | 고객 센터 문의 전화 횟수 | Integer | 배송 지연에 따른 고객 불만 척도 |\n",
            "| **Customer_rating** | 고객 만족도 점수 (1~5) | Integer | 지연 여부와 만족도의 상관관계 분석 |\n",
            "| **Cost_of_the_Product** | 제품 가격 (USD) | Integer | 고가 제품의 우선 배송 여부 확인 |\n",
            "| **Prior_purchases** | 이전 구매 횟수 | Integer | 충성 고객 대상 배송 서비스 수준 확인 |\n",
            "| **Product_importance** | 제품 중요도 (low, med, high) | Object | 중요도에 따른 배송 지연 차이 존재 여부 |\n",
            "| **Gender** | 고객 성별 (F, M) | Object | 성별에 따른 구매 패턴 차이 확인 |\n",
            "| **Discount_offered** | 할인 금액 | Integer | **핵심 가설:** 할인 폭이 크면 주문 폭주로 지연 가능성 높음 |\n",
            "| **Weight_in_gms** | 제품 무게 (g) | Integer | 무게에 따른 배송 수단 제한 및 지연 영향 |\n",
            "\n",
            "---\n",
            "\n",
            "### 3. 분석 전략 (Initial Strategy)\n",
            "\n",
            "1. **데이터 정제:** ID 컬럼 삭제 및 범주형 변수(Warehouse, Mode 등) 수치화.\n",
            "2. **핵심 가설 검증:** - 할인(`Discount_offered`)과 배송 지연(`1`)의 상관관계 분석.\n",
            "   - 제품 무게(`Weight_in_gms`)가 배송 수단별 지연에 미치는 영향 분석.\n",
            "3. **성능 지표:** 모델의 예측 성능은 **ROC-AUC** 점수를 기준으로 평가함."
         ]
      },
      {
         "cell_type": "markdown",
         "id": "bb1a24f8",
         "metadata": {},
         "source": [
            "### 0. 데이터 불러오기, 기본 코드"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "fe84123d",
         "metadata": {},
         "outputs": [],
         "source": [
            "#!/bin/bash\n",
            "# !kaggle datasets download prachi13/customer-analytics"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "80813329",
         "metadata": {},
         "outputs": [],
         "source": [
            "#import zipfile\n",
            "import os\n",
            "\n",
            "HOME = os.getcwd()\n",
            "HOME\n",
            "\n",
            "# zip_file_path = 'customer-analytics.zip'\n",
            "\n",
            "# extract_to_path = 'data'\n",
            "\n",
            "# with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
            "#     zip_ref.extractall(extract_to_path)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "3151998f",
         "metadata": {},
         "outputs": [],
         "source": [
            "import platform\n",
            "import warnings\n",
            "import pandas as pd\n",
            "import numpy as np\n",
            "import matplotlib.pyplot as plt\n",
            "import seaborn as sns\n",
            "\n",
            "# 데이터 분할 및 하이퍼파라미터 튜닝\n",
            "from sklearn.model_selection import train_test_split, GridSearchCV\n",
            "\n",
            "# 데이터 전처리 및 성능 평가 지표\n",
            "from sklearn.preprocessing import LabelEncoder\n",
            "from sklearn.metrics import (\n",
            "    accuracy_score, \n",
            "    roc_auc_score, \n",
            "    classification_report\n",
            ")\n",
            "from sklearn.metrics import precision_score, recall_score, f1_score\n",
            "\n",
            "# 머신러닝 알고리즘 (부스팅, 앙상블 등)\n",
            "from xgboost import XGBClassifier\n",
            "from lightgbm import LGBMClassifier\n",
            "from catboost import CatBoostClassifier\n",
            "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, GradientBoostingClassifier\n",
            "from sklearn.linear_model import LogisticRegression\n",
            "\n",
            "\n",
            "# 1. 환경 설정 및 경고 무시\n",
            "# ---------------------------------------------------------\n",
            "warnings.filterwarnings('ignore') # 모든 FutureWarning 및 경고 무시\n",
            "\n",
            "# 2. 한글 폰트 설정 (OS별 대응)\n",
            "# ---------------------------------------------------------\n",
            "if platform.system() == 'Darwin':     # 맥(macOS)\n",
            "    plt.rc('font', family='AppleGothic')\n",
            "elif platform.system() == 'Windows':  # 윈도우\n",
            "    plt.rc('font', family='Malgun Gothic')\n",
            "\n",
            "plt.rcParams['axes.unicode_minus'] = False # 마이너스 기호 깨짐 방지"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "9a415fe7",
         "metadata": {},
         "outputs": [],
         "source": [
            "#!/bin/bash\n",
            "# !kaggle datasets download prachi13/customer-analytics"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "80813329",
         "metadata": {},
         "outputs": [],
         "source": [
            "#import zipfile\n",
            "import os\n",
            "\n",
            "Train.head()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "25f559b7",
         "metadata": {},
         "outputs": [],
         "source": [
            "Train"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "7700e5cb",
         "metadata": {},
         "outputs": [],
         "source": [
            "Train['Reached.on.Time_Y.N'].value_counts(normalize=True) * 100"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "92292abd",
         "metadata": {},
         "source": [
            "### 1. 검증용 데이터 분리"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "633fa9f8",
         "metadata": {},
         "outputs": [],
         "source": [
            "# 1. stratify 옵션을 써서 정답(Reached.on.Time_Y.N) 비율을 유지하며 8:2로 나눕니다.\n",
            "# 이 함수는 내부적으로 데이터를 랜덤하게 섞어주기 때문에 sample을 따로 안 써도 됩니다.\n",
            "part1, part2 = train_test_split(Train, \n",
            "                                test_size=0.2, \n",
            "                                random_state=42, \n",
            "                                stratify=Train['Reached.on.Time_Y.N'])\n",
            "\n",
            "# 2. 각각 파일로 저장\n",
            "part1.to_csv('data/train_df.csv', index=False)\n",
            "part2.to_csv('data/test_df.csv', index=False)\n",
            "\n",
            "print(\"데이터 분할 및 저장 완료!\")\n",
            "print(f\"학습용: {part1.shape}, 테스트용: {part2.shape}\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "082decd9",
         "metadata": {},
         "outputs": [],
         "source": [
            "Train = pd.read_csv('data/train_df.csv')\n",
            "test = pd.read_csv('data/test_df.csv')\n",
            "\n",
            "Train.head()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "c9e372b9",
         "metadata": {},
         "outputs": [],
         "source": [
            "# 원본 비율\n",
            "print(Train['Reached.on.Time_Y.N'].value_counts(normalize=True))\n",
            "\n",
            "# 학습용 비율 (part1)\n",
            "print(part1['Reached.on.Time_Y.N'].value_counts(normalize=True))\n",
            "\n",
            "# 테스트용 비율 (part2)\n",
            "print(part2['Reached.on.Time_Y.N'].value_counts(normalize=True))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "10daba4f",
         "metadata": {},
         "outputs": [],
         "source": [
            "Train.info()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "a28c7019",
         "metadata": {},
         "outputs": [],
         "source": [
            "print(Train.columns)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "585384c1",
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "abcb43ee",
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "markdown",
         "id": "a4b4da17",
         "metadata": {},
         "source": [
            "### 2. 데이터 확인"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "ca2e23dd",
         "metadata": {},
         "outputs": [],
         "source": [
            "# [1-1] 전체적인 구조와 결측치 확인\n",
            "print(\"--- 🩺 데이터 기본 정보 ---\")\n",
            "print(Train.info())\n",
            "\n",
            "# [1-2] 수치형 데이터의 통계적 분포 (평균, 최소/최대 등)\n",
            "print(\"\\n--- 📊 수치형 데이터 요약 통계 ---\")\n",
            "display(Train.describe())"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "d101fa5c",
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "75c00d6b",
         "metadata": {},
         "outputs": [],
         "source": [
            "# 범주형 변수 분석 : 글자로 된 변수들은 '개수'와 '지연율'을 보는 게 핵심\n",
            "# 반복되는 분석은 반복문(for)으로 깔끔하게!\n",
            "cat_features = ['Warehouse_block', 'Mode_of_Shipment', 'Gender', 'Product_importance']\n",
            "\n",
            "for col in cat_features:\n",
            "    print(f\"\\n🔍 [{col}] 컬럼 상세 분석\")\n",
            "    # 1. 개수 확인\n",
            "    print(Train[col].value_counts())\n",
            "    # 2. 지연율 확인 (상관관계 파악)\n",
            "    display(Train.groupby(col)['Reached.on.Time_Y.N'].mean().sort_values(ascending=False))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "14201aeb",
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "markdown",
         "id": "c85c44e8",
         "metadata": {},
         "source": [
            "> Product_importance\n",
            "* XGBoost 모델이 이 변수를 중요하게 쓰겠지만, high 데이터의 개수가 768개로 적은 편\n",
            "* 768개가 특정 창고(Warehouse_block)에 몰려있는지 확인 후 -> 파생변수 만들지 여부 정하기\n",
            "\n",
            "> Gender --> drop (+ID)\n",
            "\n",
            "> Mode_of_Shipment\n",
            "* 배(Ship), 비행기(Flight), 도로(Road)의 지연율이 거의 비슷(0.58~0.60).\n",
            "* **'배송 수단 + 무게?'** 등을 조합한 파생변수 만들지 여부 정하기\n",
            "\n",
            "> Warehouse_block\n",
            "* F구역이 데이터는 압도적으로 많지만(2,910개), 지연율은 모든 구역이 58~60%로 일정\n",
            "* 특정 구역이나 수단의 고질적 문제라기보다, 전체적인 물류 프로세스의 공통적인 지연 요소가 있을 것으로 판단됨."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "8817433e",
         "metadata": {},
         "outputs": [],
         "source": [
            "# \"중요도(high)는 특정 창고에 몰려있을까?\"\n",
            "# 창고별 제품 중요도 분포\n",
            "importance_warehouse = pd.crosstab(Train['Warehouse_block'], Train['Product_importance'])\n",
            "print(\"--- 🏢 창고별 중요도 제품 건수 ---\")\n",
            "print(importance_warehouse)\n",
            "\n",
            "# 지연율까지 같이 보고 싶다면?\n",
            "importance_delay = Train.pivot_table(index='Warehouse_block', \n",
            "                                     columns='Product_importance', \n",
            "                                     values='Reached.on.Time_Y.N', \n",
            "                                     aggfunc='mean')\n",
            "print(\"\\n--- 🚨 창고x중요도별 지연율 (%) ---\")\n",
            "display(importance_delay * 100)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "d40edfb6",
         "metadata": {},
         "source": [
            "> 창고 A는 중요도 high 제품 지연율이 70.08% / 유독 중요한 물건을 다룰 때 병목현상이 심하게 일어남 \n",
            "* 근데 데이터 개수 127개 >> 파생변수는 만들지 않는 게 더 나은 선택 (일반화 하기에 너무 작은 표본)\n",
            "* XGBoost 돌리면 알아서 처리"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "555ae2cf",
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "2c1f3beb",
         "metadata": {},
         "outputs": [],
         "source": [
            "# 숫자형 변수 분석 : 분포 + 이상치 확인\n",
            "num_features = ['Discount_offered', 'Weight_in_gms', 'Cost_of_the_Product', 'Prior_purchases']\n",
            "\n",
            "plt.figure(figsize=(15, 10))\n",
            "for i, col in enumerate(num_features, 1):\n",
            "    plt.subplot(2, 2, i)\n",
            "    sns.histplot(Train[col], kde=True)\n",
            "    plt.title(f'{col} Distribution')\n",
            "plt.tight_layout()\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "86678588",
         "metadata": {},
         "source": [
            "> Discount_offered (할인) - ⚠️ 10.5 (지니계수가 가장 적은 게 10.5라고 계산함)\n",
            "* $10.5$달러 이상의 고액 할인은 주문 폭주를 일으켜 과부하되는 듯\n",
            "\n",
            "> Weight_in_gms (제품 무게) - 🚨 위험 구간 2~4kg\n",
            "* 특정 무게 구간(2,000g~4,000g)에서 지연 데이터가 비정상적으로 많이 관찰\n",
            "* 어중간한 2~4kg 무게가 포장이나 적재 시 가장 많이 지연되는 '데드 존(Dead Zone)'\n",
            "\n",
            "*** 가설1 : 할인 품목이 2~4kg가 많지 않을까 하는 생각<br>\n",
            "*** 가설2 : 가벼운것/무거운것보다 중간이 많으니까 어디 밀려났다가 한꺼번에 처리하지 않을까 하는 추측\n",
            "\n",
            "> Cost_of_the_Product (제품 가격)\n",
            "* 어느 한 곳에 쏠리지 않고 골고루 분포됨. 무게랑 같이 엮어서 **'무게 대비 가격(Value Density)'** 파생 변수를 만들기\n",
            "\n",
            "> Prior_purchases(이전 구매 횟수)\n",
            "* 3회 구매자가 가장 많고, 6회 이상부터는 데이터가 확 줄어듦\n",
            "* 재구매 6회 이상 단골고객 패턴은 비슷하니, 모델이 헷갈리지 않게 하나로 묶어주기"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "f7b627d0",
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "markdown",
         "id": "ea865645",
         "metadata": {},
         "source": [
            "> Weight_in_gms 가설 확인\n",
            "* 가설1 : 할인 품목이 2~4kg가 많아서 지연<br>\n",
            "* 가설2 : 가벼운것/무거운것보다 중간 무게가 많아서 물량이 많은만큼 지연"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "5135d4fd",
         "metadata": {},
         "outputs": [],
         "source": [
            "# [1] 무게 구간 나누기 (2~4kg를 집중적으로 보기 위함)\n",
            "def categorize_weight(w):\n",
            "    if w < 2000: return '1. Small (<2kg)'\n",
            "    elif 2000 <= w <= 4000: return '2. Medium (2-4kg)'\n",
            "    else: return '3. Large (>4kg)'\n",
            "\n",
            "# 전처리 중인 데이터프레임(Train)에 적용\n",
            "Train['Weight_Group'] = Train['Weight_in_gms'].apply(categorize_weight)\n",
            "\n",
            "# [2] 가설 1 확인: \"2~4kg에 할인 품목이 몰려 있는가?\"\n",
            "# 무게 구간별 할인액(Discount_offered)의 평균과 중앙값 확인\n",
            "discount_analysis = Train.groupby('Weight_Group')['Discount_offered'].agg(['mean', 'median', 'count'])\n",
            "print(\"--- 💸 무게 구간별 할인액 통계 ---\")\n",
            "print(discount_analysis)\n",
            "\n",
            "# [3] 가설 2 확인: \"2~4kg 물량이 압도적으로 많아서 밀리는가?\"\n",
            "# 위에서 구한 'count' 컬럼이 바로 물동량(Volume)\n",
            "print(\"\\n--- 📦 무게 구간별 물동량(건수) 비교 ---\")\n",
            "print(Train['Weight_Group'].value_counts(normalize=True) * 100) # 퍼센트로 보기\n",
            "\n",
            "# [4] 시각화로 한눈에 확인 (Boxplot + Countplot)\n",
            "plt.figure(figsize=(15, 6))\n",
            "\n",
            "# 왼쪽: 할인율 분포 (가설 1 검증)\n",
            "plt.subplot(1, 2, 1)\n",
            "sns.boxplot(data=Train, x='Weight_Group', y='Discount_offered', palette='Set2')\n",
            "plt.axhline(10.5, color='red', linestyle='--', label='High Discount Line')\n",
            "plt.title('Weight Group vs Discount')\n",
            "\n",
            "# 오른쪽: 물동량 확인 (가설 2 검증)\n",
            "plt.subplot(1, 2, 2)\n",
            "sns.countplot(data=Train, x='Weight_Group', palette='Set3')\n",
            "plt.title('Package Volume by Weight Group')\n",
            "\n",
            "plt.tight_layout()\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "0e4a2123",
         "metadata": {},
         "source": [
            "> 결과\n",
            "\n",
            "**가설1** ⭕\n",
            "* 2~4kg 그룹의 평균할인액 32.69 중앙값 34.0\n",
            "* 다른 그룹(Small: 16.7달러, Large: 5.5달러)과 비교하면 압도적으로 높은 할인이 이 구간에 쏠림\n",
            "* 기업이 가장 공격적으로 프로모션을 진행하는 '전략 상품군'이 바로 이 2~4kg 무게대에 집중되어 있다\n",
            "\n",
            "**가설2** ❌\n",
            "* 물동량 1위는 Large (>4kg) 그룹으로,53.9%\n",
            "* Medium (2-4kg) 16.5% - 물량이 가장 적음\n",
            "* 물량이 많아서 밀리는 게 아니라 '할인 폭이 너무 커서' 주문이 한꺼번에 몰리거나, 특별 관리가 필요해서 지연되는 '프로모션의 함정' 구간임"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "828745f0",
         "metadata": {},
         "outputs": [],
         "source": [
            "# [Section 2-6] 2~4kg 구간(Danger Zone) 내부의 할인율 분포 및 비중 확인\n",
            "\n",
            "# 1. 2~4kg 데이터만 필터링\n",
            "danger_weight_df = Train[(Train['Weight_in_gms'] >= 2000) & (Train['Weight_in_gms'] <= 4000)]\n",
            "\n",
            "# 2. 시각화 (지연 여부로 색깔 구분!)\n",
            "plt.figure(figsize=(12, 6))\n",
            "sns.histplot(data=danger_weight_df, x='Discount_offered', hue='Reached.on.Time_Y.N', \n",
            "             kde=True, palette='magma', element=\"step\")\n",
            "\n",
            "# 3. 10.5 선 긋기\n",
            "plt.axvline(10.5, color='red', linestyle='--', linewidth=2, label='Magic Line: 10.5$')\n",
            "\n",
            "plt.title('📦 2~4kg 구간 내 할인율 분포 (지연 여부 포함)', fontsize=16)\n",
            "plt.xlabel('Discount Offered ($)', fontsize=12)\n",
            "plt.ylabel('Count', fontsize=12)\n",
            "plt.legend(title='Delayed?', labels=['Delayed (1)', 'On Time (0)', 'Threshold'])\n",
            "plt.grid(axis='y', alpha=0.3)\n",
            "plt.show()\n",
            "\n",
            "# 4. 수치 확인\n",
            "total_cnt = len(danger_weight_df)\n",
            "high_discount_cnt = len(danger_weight_df[danger_weight_df['Discount_offered'] > 10.5])\n",
            "percentage = (high_discount_cnt / total_cnt) * 100 if total_cnt > 0 else 0\n",
            "\n",
            "print(f\"--- 📊 2~4kg 구간 심층 통계 ---\")\n",
            "print(f\"1. 전체 건수: {total_cnt}건\")\n",
            "print(f\"2. 10.5$ 초과 고액 할인 건수: {high_discount_cnt}건\")\n",
            "print(f\"3. 고액 할인 비중: 🔥 {percentage:.1f}% 🔥\") # 소수점 첫째자리까지 표시"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "22304f50",
         "metadata": {},
         "source": [
            "> 무게(Weight)와 할인(Discount)의 관계\n",
            "\n",
            "제품 무게 2,000g~4,000g 구간은 물동량 비중은 **16.5%**로 가장 낮지만, 평균 할인액은 32.69달러로 타 구간 대비 압도적으로 높음.\n",
            "\n",
            "결론: 해당 구간의 높은 지연율은 '물량 과부하' 때문이 아니라, 고액 할인이 집중된 프로모션 상품들의 주문 처리 과정에서 발생하는 병목 현상이 주원인으로 분석됨.\n",
            "\n",
            "전략: 따라서 Is_Danger_Weight 파생 변수는 단순히 무게를 보는 것이 아니라, **'고할인 전략 상품군'을 식별하는 대리 변수(Proxy Variable)**로서 강력한 예측력을 가지게 됨."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "b7a55386",
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "e335bfd1",
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "markdown",
         "id": "54d71cd1",
         "metadata": {},
         "source": [
            "### 🛠️ 3. Feature Engineering (변수 생성 및 데이터 정제)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "ad40ac94",
         "metadata": {},
         "outputs": [],
         "source": [
            "# [1] 팀 규칙: 즉시 8:2 분할 (분석의 신뢰도를 위해 전처리 전 수행)\n",
            "train_data, val_data = train_test_split(\n",
            "    Train, test_size=0.2, random_state=42, stratify=Train['Reached.on.Time_Y.N']\n",
            ")\n",
            "\n",
            "# [2] 정예 멤버 11인을 위한 최종 전처리 함수 정의\n",
            "def get_final_master_df(df):\n",
            "    temp = df.copy()\n",
            "    \n",
            "    # 1. 핵심 파생 변수 생성 (할인, 무게, 가치밀도)\n",
            "    temp['Is_High_Discount'] = (temp['Discount_offered'] > 10.5).astype(int)\n",
            "    temp['Is_Danger_Weight'] = temp['Weight_in_gms'].between(2000, 4000).astype(int)\n",
            "    temp['Value_Density'] = temp['Cost_of_the_Product'] / temp['Weight_in_gms']\n",
            "    \n",
            "    # 2. 범주형 데이터 수치화 및 클리닝\n",
            "    temp['Prior_purchases'] = temp['Prior_purchases'].apply(lambda x: 6 if x >= 6 else x)\n",
            "    mapping = {'low': 1, 'medium': 2, 'high': 3}\n",
            "    if temp['Product_importance'].dtype == 'object':\n",
            "        temp['Product_importance'] = temp['Product_importance'].str.lower().map(mapping)\n",
            "    \n",
            "    # 3. 기타 범주형 인코딩\n",
            "    cat_cols = ['Warehouse_block', 'Mode_of_Shipment', 'Customer_rating']\n",
            "    for col in cat_cols:\n",
            "        if col in temp.columns:\n",
            "            temp[col] = pd.Categorical(temp[col]).codes\n",
            "            \n",
            "    # 4. 정예 11개 변수 + 타겟 변수 선택\n",
            "    final_features = [\n",
            "        'Discount_offered', 'Is_Danger_Weight', 'Warehouse_block', \n",
            "        'Cost_of_the_Product', 'Customer_care_calls', 'Weight_in_gms', \n",
            "        'Value_Density', 'Mode_of_Shipment', 'Customer_rating', \n",
            "        'Prior_purchases', 'Product_importance', 'Reached.on.Time_Y.N'\n",
            "    ]\n",
            "    return temp[[f for f in final_features if f in temp.columns]]\n",
            "\n",
            "# [3] 전처리 실행 및 데이터 준비\n",
            "Train_ready = get_final_master_df(train_data)\n",
            "Val_ready = get_final_master_df(val_data)\n",
            "\n",
            "X_train = Train_ready.drop(columns=['Reached.on.Time_Y.N'])\n",
            "y_train = Train_ready['Reached.on.Time_Y.N']\n",
            "X_val = Val_ready.drop(columns=['Reached.on.Time_Y.N'])\n",
            "y_val = Val_ready['Reached.on.Time_Y.N']\n",
            "\n",
            "print(f\"✅ 전처리 완료! 학습용: {X_train.shape}, 검증용: {X_val.shape}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "24cc70d8",
         "metadata": {},
         "source": [
            "### 🤖 4. 모델 학습 및 검증 (Model Training)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "471a3ca5",
         "metadata": {},
         "outputs": [],
         "source": [
            "# [1] 그리드 서치로 검증된 최적의 모델\n",
            "final_model = XGBClassifier(\n",
            "    n_estimators=1000, \n",
            "    learning_rate=0.005,    # 최적값 반영\n",
            "    max_depth=2,            # 최적값 반영\n",
            "    subsample=0.8,          # 최적값 반영\n",
            "    colsample_bytree=0.8, \n",
            "    random_state=42,\n",
            "    eval_metric='logloss', \n",
            "    early_stopping_rounds=100 # 보폭이 작으니 조금 더 끈기있게 지켜봄\n",
            ")\n",
            "\n",
            "# [2] 최종 학습 시작\n",
            "final_model.fit(\n",
            "    X_train, y_train, \n",
            "    eval_set=[(X_val, y_val)], \n",
            "    verbose=100\n",
            ")\n",
            "\n",
            "# [3] 🏥 최종 건강 진단 (성적표)\n",
            "train_auc = roc_auc_score(y_train, final_model.predict_proba(X_train)[:, 1])\n",
            "val_auc = roc_auc_score(y_val, final_model.predict_proba(X_val)[:, 1])\n",
            "\n",
            "print(f\"\\n\" + \"=\"*45)\n",
            "print(f\"🏆 [마스터 피스 완성] 최종 성적표\")\n",
            "print(f\"연습 점수(Train AUC): {train_auc:.4f}\")\n",
            "print(f\"실전 점수(Val AUC)  : {val_auc:.4f}\")\n",
            "print(f\"점수 차이(Gap)       : {abs(train_auc - val_auc):.4f}\")\n",
            "print(\"=\"*45)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "70aa56c6",
         "metadata": {},
         "source": [
            "#### 모델성능올리기"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "754bd509",
         "metadata": {},
         "outputs": [],
         "source": [
            "# # [1] 하이퍼파라미터 튜닝 (GridSearchCV)\n",
            "# param_grid = {\n",
            "#     'max_depth': [2, 3, 4],\n",
            "#     'learning_rate': [0.005, 0.01, 0.05],\n",
            "#     'subsample': [0.7, 0.8]\n",
            "# }\n",
            "\n",
            "# grid_search = GridSearchCV(\n",
            "#     XGBClassifier(n_estimators=500, eval_metric='logloss', random_state=42),\n",
            "#     param_grid, cv=3, scoring='roc_auc', n_jobs=-1\n",
            "# )\n",
            "\n",
            "# grid_search.fit(X_train, y_train)\n",
            "# print(f\"최적 파라미터: {grid_search.best_params_}\")\n",
            "# print(f\"최적 검증 AUC: {grid_search.best_score_:.4f}\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "ba26b6f5",
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "b93b938e",
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "markdown",
         "id": "f117ee3f",
         "metadata": {},
         "source": [
            "### 5. 모델 검증, 시각화"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "5b20bbdb",
         "metadata": {},
         "outputs": [],
         "source": [
            "# 학습 시작\n",
            "master_model.fit(\n",
            "    X_train, y_train, \n",
            "    eval_set=[(X_val, y_val)], \n",
            "    verbose=0 \n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "754bd509",
         "metadata": {},
         "outputs": [],
         "source": [
            "# [1] 하이퍼파라미터 튜닝 (GridSearchCV)\n",
            "param_grid = {\n",
            "    'max_depth': [2, 3, 4],\n",
            "    'learning_rate': [0.005, 0.01, 0.05],\n",
            "    'subsample': [0.7, 0.8]\n",
            "}\n",
            "\n",
            "grid_search = GridSearchCV(\n",
            "    XGBClassifier(n_estimators=500, eval_metric='logloss', random_state=42),\n",
            "    param_grid, cv=3, scoring='roc_auc', n_jobs=-1\n",
            ")\n",
            "\n",
            "grid_search.fit(X_train, y_train)\n",
            "print(f\"최적 파라미터: {grid_search.best_params_}\")\n",
            "print(f\"최적 검증 AUC: {grid_search.best_score_:.4f}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "466a8bc4",
         "metadata": {},
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "c70b84f7",
         "metadata": {},
         "outputs": [],
         "source": [
            "# [Step 1] 모든 실험 데이터 통합\n",
            "# Accuracy는 마지막 실행 결과를 확인해서 넣어주세요 (보통 0.67~0.68 수준)\n",
            "final_results = {\n",
            "    'Model_Strategy': [\n",
            "        'Final Tuned (Depth 2) 🏆',\n",
            "        'Option B (Lean 11)', \n",
            "        'Option A (All 16)', \n",
            "        'XGBoost (Tuned)', \n",
            "        'LightGBM (Tuned)', \n",
            "        'Random Forest (Tuned)', \n",
            "        'Stacking Ensemble', \n",
            "        'CatBoost (Single)', \n",
            "        'XGBoost (Default)'\n",
            "    ],\n",
            "    'Accuracy': [0.6710, 0.6710, 0.6642, 0.6813, 0.6795, 0.6805, 0.6756, 0.6676, 0.6472],\n",
            "    'Train_AUC': [0.7767, 0.7512, 0.8004, 0.7950, 0.7880, 0.8120, 0.8010, 0.7920, 0.8250],\n",
            "    'ROC-AUC': [0.7348, 0.7327, 0.7297, 0.7280, 0.7265, 0.7250, 0.7210, 0.7180, 0.7150]\n",
            "}\n",
            "\n",
            "# [Step 2] 데이터프레임 변환 및 Gap 계산\n",
            "df_final = pd.DataFrame(final_results)\n",
            "df_final['Gap'] = df_final['Train_AUC'] - df_final['ROC-AUC']\n",
            "\n",
            "# [Step 3] ROC-AUC(실전 판단력) 기준으로 정렬\n",
            "df_sorted = df_final.sort_values(by='ROC-AUC', ascending=False).reset_index(drop=True)\n",
            "df_sorted.index = df_sorted.index + 1\n",
            "\n",
            "# [Step 4] 시각화 출력\n",
            "print(\"--- 🏆 [최종 결산] 전 실험 모델 성적 (ROC-AUC & Gap 기준) ---\")\n",
            "# Gap은 작을수록 좋으므로(녹색), 클수록 빨간색(RdYlGn_r)으로 표시합니다.\n",
            "display(df_sorted.style.background_gradient(cmap='RdYlGn_r', subset=['Gap'])\n",
            "                  .highlight_max(axis=0, subset=['ROC-AUC', 'Accuracy'], color='lightgreen')\n",
            "                  .format('{:.4f}', subset=['Accuracy', 'Train_AUC', 'ROC-AUC', 'Gap']))"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "d184f240",
         "metadata": {},
         "source": [
            "* Final Tuned (Depth 2) 🏆 : Option B에서 GridSearchCV로 조합 찾은 것(max_depth=2, learning rate=0.005)\n",
            "* Option B보다 조금 더 깊이 있게 공부하면서도, 선을 넘지 않게(과적합 방지) 튜닝이 아주 잘 된 결과물입니다.\n",
            "\n",
            "** Gap = Train AUC - ROC-AUC\n",
            "* Option B: 연습 때 75점, 실전에서 73점 (격차 2점)\n",
            "* Final Tuned: 연습 때 77점, 실전에서 74점 (격차 3점)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "1365f337",
         "metadata": {},
         "outputs": [],
         "source": [
            "# 변수 중요도 추출\n",
            "importances = pd.DataFrame({\n",
            "    'Feature': X_train.columns,\n",
            "    'Importance': final_model.feature_importances_\n",
            "}).sort_values(by='Importance', ascending=False)\n",
            "\n",
            "# 시각화\n",
            "plt.figure(figsize=(10, 6))\n",
            "sns.barplot(x='Importance', y='Feature', data=importances, palette='magma')\n",
            "plt.title('🏆 최종 모델이 판단한 핵심 지연 요인 (Feature Importance)')\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "7c085aad",
         "metadata": {},
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "98f46f37",
         "metadata": {},
         "outputs": [],
         "source": [
            "# 중복 데이터 빼고 결과값\n",
            "\n",
            "# [1] 데이터 다이어트: 중복된 원본 할인(Discount_offered) 컬럼 제거\n",
            "# ---------------------------------------------------------\n",
            "# 기존에 정의된 X_train, X_val에서 'Discount_offered'만 쏙 뺍니다.\n",
            "X_train_slim = X_train.drop(columns=['Discount_offered'])\n",
            "X_val_slim = X_val.drop(columns=['Discount_offered'])\n",
            "\n",
            "# [2] 최적의 파라미터로 다시 학습 (이미 검증된 약효!)\n",
            "# ---------------------------------------------------------\n",
            "final_model_slim = XGBClassifier(\n",
            "    n_estimators=1000, \n",
            "    learning_rate=0.005,    # 최적값\n",
            "    max_depth=2,            # 최적값\n",
            "    subsample=0.8,          # 최적값\n",
            "    colsample_bytree=0.8, \n",
            "    random_state=42,\n",
            "    eval_metric='logloss', \n",
            "    early_stopping_rounds=100\n",
            ")\n",
            "\n",
            "# 학습 시작\n",
            "final_model_slim.fit(\n",
            "    X_train_slim, y_train, \n",
            "    eval_set=[(X_val_slim, y_val)], \n",
            "    verbose=100\n",
            ")\n",
            "\n",
            "# [3] 성적표 산출\n",
            "# ---------------------------------------------------------\n",
            "train_auc_slim = roc_auc_score(y_train, final_model_slim.predict_proba(X_train_slim)[:, 1])\n",
            "val_auc_slim = roc_auc_score(y_val, final_model_slim.predict_proba(X_val_slim)[:, 1])\n",
            "\n",
            "print(f\"\\n\" + \"=\"*45)\n",
            "print(f\"✨ [중복 제거 완료] 최종 정예 모델 성적\")\n",
            "print(f\"연습 점수(Train AUC): {train_auc_slim:.4f}\")\n",
            "print(f\"실전 점수(Val AUC)  : {val_auc_slim:.4f}\")\n",
            "print(f\"점수 차이(Gap)       : {abs(train_auc_slim - val_auc_slim):.4f}\")\n",
            "print(\"=\"*45)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "a2acb020",
         "metadata": {},
         "outputs": [],
         "source": [
            "# [Step 1] 모든 실험 데이터 통합 (슬림 버전 추가!)\n",
            "final_results = {\n",
            "    'Model_Strategy': [\n",
            "        'Final Masterpiece (Slim) ✨', # 변수 10개로 다이어트한 최종본\n",
            "        'Final Tuned (Depth 2) 🏆',    # 변수 11개 튜닝본\n",
            "        'Option B (Lean 11)', \n",
            "        'Option A (All 16)', \n",
            "        'XGBoost (Tuned)', \n",
            "        'LightGBM (Tuned)', \n",
            "        'Random Forest (Tuned)', \n",
            "        'Stacking Ensemble', \n",
            "        'CatBoost (Single)', \n",
            "        'XGBoost (Default)'\n",
            "    ],\n",
            "    'Accuracy': [0.6710, 0.6710, 0.6710, 0.6642, 0.6813, 0.6795, 0.6805, 0.6756, 0.6676, 0.6472],\n",
            "    'Train_AUC': [0.7754, 0.7767, 0.7512, 0.8004, 0.7950, 0.7880, 0.8120, 0.8010, 0.7920, 0.8250],\n",
            "    'ROC-AUC': [0.7321, 0.7348, 0.7327, 0.7297, 0.7280, 0.7265, 0.7250, 0.7210, 0.7180, 0.7150]\n",
            "}\n",
            "\n",
            "# [Step 2] 데이터프레임 변환 및 Gap 계산\n",
            "df_final = pd.DataFrame(final_results)\n",
            "df_final['Gap'] = df_final['Train_AUC'] - df_final['ROC-AUC']\n",
            "\n",
            "# [Step 3] ROC-AUC(실전 판단력) 기준으로 정렬\n",
            "df_sorted = df_final.sort_values(by='ROC-AUC', ascending=False).reset_index(drop=True)\n",
            "df_sorted.index = df_sorted.index + 1\n",
            "\n",
            "# [Step 4] 시각화 출력\n",
            "print(\"--- 🏆 [최종 결산] 전 실험 모델 성적 (ROC-AUC & Gap 기준) ---\")\n",
            "display(df_sorted.style.background_gradient(cmap='RdYlGn_r', subset=['Gap'])\n",
            "                  .highlight_max(axis=0, subset=['ROC-AUC', 'Accuracy'], color='lightgreen')\n",
            "                  .format('{:.4f}', subset=['Accuracy', 'Train_AUC', 'ROC-AUC', 'Gap']))"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "af9025fa",
         "metadata": {},
         "source": [
            "**최종 총평**\n",
            "\n",
            "TOP 3: 1위부터 3위까지 모두 우리가 직접 설계한 **파생 변수(Is_High_Discount, Is_Danger_Weight)**를 사용한 모델들입니다. 데이터의 본질을 꿰뚫는 피처 엔지니어링이 얼마나 중요한지 증명되었습니다.\n",
            "\n",
            "슬림 모델의 가치 (3위): **'Final Masterpiece (Slim)'**은 중복되는 할인 금액 변수를 제거했음에도 불구하고, 여전히 상위권의 판단력($0.7321$)을 유지하고 있습니다. 변수 10개만으로 이 정도 성적을 낸다는 것은 모델의 효율성이 매우 극대화되었다는 뜻입니다.\n",
            "\n",
            "과적합(Overfitting) 해결: 10위 모델인 Default XGBoost의 Gap($0.1100$)과 비교해 보세요. 우리가 만든 상위권 모델들은 모두 $0.05$ 이내의 건강한 Gap을 보여주고 있습니다."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "7e566a1f",
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "e5d50eea",
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "4d766177",
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "04a40119",
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "markdown",
         "id": "8c1bc1ac",
         "metadata": {},
         "source": [
            "1. 정확도 (Accuracy) : \"전체 문제 중 맞힌 정답의 비율\"\n",
            "2. ROC-AUC : \"스팸을 스팸으로, 일반 메일을 일반 메일로 골라내는 변별력\"\n",
            "* 지연되는 택배를 골라내는 것이 목적이다 >> ROC-AUC\n",
            "* 전체적인 배송 성공률 자체가 궁금하다 >> Accuracy\n",
            "* 며칠 걸릴지 시간을 맞추는 중이다 >> MAE / RMSE"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "889c10a2",
         "metadata": {},
         "source": [
            "### 그래서 어떻게 대비?\n",
            "* CS 선제 액션: 모델이 지연될 확률이 높다고 찍은 고객들에게는 미리 주문 폭주로 지연될 수 있다는 문자와 포인트 등 보상을 해줌. / 고객은 늦게 받는 것 뿐 아니라 아무 말 없이 늦을 때 화가 나는 경우가 많음. \n",
            "\n",
            "* 물류 라인 조정: 우리가 만든 Is_Danger_Weight($2$~$4kg$)나 고액 할인 품목들은 모델이 위험하다고 판단한 조건임. / 이런 물건들은 전용 특급 라인으로 배정하거나 포장 순서를 앞으로 당겨서 지연을 강제로 막아버리기. (물류가 그게 가능하다면)"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "DS",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.14"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 5
}

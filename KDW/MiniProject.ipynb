{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from xgboost import XGBClassifier\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.metrics import accuracy_score, classification_report\n",
                "\n",
                "# 1. 데이터를 다시 로드 (변수명을 완전히 새로 정의해서 꼬임을 방지합니다)\n",
                "try:\n",
                "    df_main = pd.read_csv('data/Train.csv')\n",
                "except FileNotFoundError:\n",
                "    df_main = pd.read_csv('Train.csv') # 경로가 다를 경우 대비\n",
                "\n",
                "# 컬럼명 정리 (공백 제거)\n",
                "df_main.columns = df_main.columns.str.strip()\n",
                "\n",
                "# 2. 전처리 (df_main을 사용하여 안전하게 진행)\n",
                "# 만약 'Discount_offered'가 진짜 없다면 여기서 프로그램이 멈추지 않고 경고를 줍니다.\n",
                "if 'Discount_offered' not in df_main.columns:\n",
                "    raise ValueError(f\"파일에 'Discount_offered' 컬럼이 없습니다! 현재 컬럼: {df_main.columns.tolist()}\")\n",
                "\n",
                "# 피처 엔지니어링\n",
                "df_main['Is_High_Discount'] = (df_main['Discount_offered'] > 10).astype(int)\n",
                "df_main['Weight_Type'] = pd.cut(df_main['Weight_in_gms'], \n",
                "                                bins=[0, 2000, 4000, 6000, 10000], \n",
                "                                labels=[0, 1, 2, 3]).astype(int)\n",
                "df_main['Cost_per_Weight'] = df_main['Cost_of_the_Product'] / (df_main['Weight_in_gms'] + 1)\n",
                "\n",
                "# 범주형 인코딩\n",
                "le = LabelEncoder()\n",
                "categorical_cols = ['Warehouse_block', 'Mode_of_Shipment', 'Product_importance', 'Gender']\n",
                "for col in categorical_cols:\n",
                "    df_main[col] = le.fit_transform(df_main[col].astype(str))\n",
                "\n",
                "# 3. 모델링용 데이터 분리 (Target 컬럼명도 strip으로 정리했으니 안심하세요)\n",
                "X = df_main.drop(['ID', 'Reached.on.Time_Y.N'], axis=1)\n",
                "y = df_main['Reached.on.Time_Y.N']\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "# 4. XGBoost 학습\n",
                "final_model = XGBClassifier(\n",
                "    n_estimators=500,        # 더 많이 반복 학습\n",
                "    learning_rate=0.01,      # 더 천천히, 꼼꼼하게 학습\n",
                "    max_depth=4,             # 너무 깊으면 과적합되니 적당히 조절\n",
                "    min_child_weight=3,      # 가지치기를 좀 더 엄격하게\n",
                "    subsample=0.8,\n",
                "    colsample_bytree=0.8,\n",
                "    eval_metric='logloss',\n",
                "    random_state=42\n",
                ")\n",
                "\n",
                "final_model.fit(X_train, y_train)\n",
                "\n",
                "# 5. 결과\n",
                "y_pred = final_model.predict(X_test)\n",
                "print(f\"최종 정확도: {accuracy_score(y_test, y_pred):.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# 1. 변수 중요도 추출\n",
                "importances = final_model.feature_importances_\n",
                "feature_names = X.columns\n",
                "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
                "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
                "\n",
                "# 2. 시각화\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.barplot(x='Importance', y='Feature', data=feature_importance_df, palette='viridis')\n",
                "plt.title('What Drives Delivery Delays? (Feature Importance)', fontsize=15)\n",
                "plt.xlabel('Importance Score')\n",
                "plt.ylabel('Features')\n",
                "plt.show()\n",
                "\n",
                "# 3. 상위 5개 변수 출력\n",
                "print(\"모델이 가장 중요하게 생각하는 TOP 5 변수:\")\n",
                "print(feature_importance_df.head(5))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# pip install shap (설치가 필요할 수 있습니다)\n",
                "import shap\n",
                "\n",
                "# SHAP 값 계산\n",
                "explainer = shap.TreeExplainer(final_model)\n",
                "shap_values = explainer.shap_values(X_test)\n",
                "\n",
                "# 요약 그래프 (전체적인 영향력)\n",
                "shap.summary_plot(shap_values, X_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from xgboost import XGBClassifier\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# 1. 데이터 로드 및 전처리\n",
                "df = pd.read_csv('data/Train.csv')\n",
                "\n",
                "# 피처 엔지니어링 (우리가 찾은 전환점들)\n",
                "df['Is_High_Discount'] = (df['Discount_offered'] > 10).astype(int)\n",
                "df['Weight_DeadZone'] = df['Weight_in_gms'].apply(lambda x: 1 if 2000 <= x <= 4000 else 0)\n",
                "\n",
                "# 범주형 변수 처리\n",
                "le = LabelEncoder()\n",
                "for col in ['Warehouse_block', 'Mode_of_Shipment', 'Product_importance', 'Gender']:\n",
                "    df[col] = le.fit_transform(df[col])\n",
                "\n",
                "X = df.drop(['ID', 'Reached.on.Time_Y.N'], axis=1)\n",
                "y = df['Reached.on.Time_Y.N']\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "# 2. XGBoost 모델 생성 및 학습\n",
                "# learning_rate와 max_depth를 조절해 오답을 세밀하게 교정합니다.\n",
                "xgb_model = XGBClassifier(\n",
                "    n_estimators=200,\n",
                "    learning_rate=0.05,\n",
                "    max_depth=6,\n",
                "    subsample=0.8,\n",
                "    colsample_bytree=0.8,\n",
                "    use_label_encoder=False,\n",
                "    eval_metric='logloss',\n",
                "    random_state=42\n",
                ")\n",
                "\n",
                "xgb_model.fit(X_train, y_train)\n",
                "\n",
                "# 3. 결과 확인\n",
                "y_pred = xgb_model.predict(X_test)\n",
                "print(f\"XGBoost 최종 정확도: {accuracy_score(y_test, y_pred):.4f}\")\n",
                "print(\"\\n[분류 보고서]\\n\", classification_report(y_test, y_pred))\n",
                "\n",
                "# 4. 혼동 행렬(Confusion Matrix) 시각화\n",
                "# 모델이 정시 도착(0)과 지연(1) 중 어디를 더 잘 맞추는지 확인합니다.\n",
                "plt.figure(figsize=(7, 5))\n",
                "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
                "plt.xlabel('Predicted')\n",
                "plt.ylabel('Actual')\n",
                "plt.title('Confusion Matrix')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from xgboost import XGBClassifier\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.metrics import accuracy_score, classification_report\n",
                "\n",
                "# [1] 데이터 로드 및 컬럼 정리\n",
                "df = pd.read_csv('data/Train.csv')\n",
                "df.columns = df.columns.str.strip()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# [2] EDA: 어떤 컬럼이 의미 있는지 시각화로 확인\n",
                "# 지연 여부에 따른 할인율과 무게의 분포 확인\n",
                "plt.figure(figsize=(10, 4))\n",
                "sns.violinplot(x='Reached.on.Time_Y.N', y='Discount_offered', data=df)\n",
                "plt.title(\"Discount offered by Delay Status\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# [3] 피처 엔지니어링 (우리가 찾아낸 핵심 로직)\n",
                "df['Is_High_Discount'] = (df['Discount_offered'] > 10).astype(int)\n",
                "df['Weight_DeadZone'] = df['Weight_in_gms'].apply(lambda x: 1 if 2000 <= x <= 4000 else 0)\n",
                "df['Cost_per_Weight'] = df['Cost_of_the_Product'] / (df['Weight_in_gms'] + 1)\n",
                "\n",
                "# 범주형 변수 인코딩\n",
                "le = LabelEncoder()\n",
                "for col in ['Warehouse_block', 'Mode_of_Shipment', 'Product_importance', 'Gender']:\n",
                "    df[col] = le.fit_transform(df[col].astype(str))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# [4] 팀의 방식대로 데이터 분할 (0.2 비율, stratify 적용)\n",
                "X = df.drop(['ID', 'Reached.on.Time_Y.N'], axis=1)\n",
                "y = df['Reached.on.Time_Y.N']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# stratify=y를 넣어 지연 비율을 6:4로 일정하게 유지합니다.\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42, stratify=y\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# [5] 모델링 및 하이퍼파라미터 튜닝\n",
                "# 점수를 쥐어짜기 위한 세밀한 설정\n",
                "final_model = XGBClassifier(\n",
                "    n_estimators=500,\n",
                "    learning_rate=0.01,\n",
                "    max_depth=5,\n",
                "    subsample=0.8,\n",
                "    colsample_bytree=0.8,\n",
                "    eval_metric='logloss',\n",
                "    random_state=42\n",
                ")\n",
                "\n",
                "final_model.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# [6] 최종 결과 및 변수 중요도 시각화\n",
                "y_pred = final_model.predict(X_test)\n",
                "print(f\"최종 정확도: {accuracy_score(y_test, y_pred):.4f}\")\n",
                "\n",
                "# 어떤 컬럼이 가장 기여를 했는가?\n",
                "importances = pd.Series(final_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.barplot(x=importances, y=importances.index)\n",
                "plt.title(\"Final Feature Importance\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.feature_selection import mutual_info_classif\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "\n",
                "# 데이터 로드\n",
                "df = pd.read_csv('data/Train.csv')\n",
                "\n",
                "# 1. 상호정보량 (Mutual Information) 계산\n",
                "# 범주형 변수를 임시로 인코딩하여 전체적인 의존성을 확인합니다.\n",
                "df_mi = df.copy().drop(['ID'], axis=1)\n",
                "le = LabelEncoder()\n",
                "for col in df_mi.select_dtypes(include='object').columns:\n",
                "    df_mi[col] = le.fit_transform(df_mi[col])\n",
                "\n",
                "X = df_mi.drop('Reached.on.Time_Y.N', axis=1)\n",
                "y = df_mi['Reached.on.Time_Y.N']\n",
                "\n",
                "mi_scores = mutual_info_classif(X, y, random_state=42)\n",
                "mi_results = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns).sort_values(ascending=False)\n",
                "\n",
                "# 2. 시각화: 상호정보량 순위\n",
                "plt.figure(figsize=(10, 5))\n",
                "sns.barplot(x=mi_results.values, y=mi_results.index)\n",
                "plt.title(\"Mutual Information Scores (Non-linear Relationship)\")\n",
                "plt.show()\n",
                "\n",
                "# 3. 중요 범주형 변수 분석 (Product_importance vs 지연율)\n",
                "plt.figure(figsize=(8, 5))\n",
                "sns.barplot(x='Product_importance', y='Reached.on.Time_Y.N', data=df)\n",
                "plt.title(\"Delay Rate by Product Importance\")\n",
                "plt.axhline(df['Reached.on.Time_Y.N'].mean(), color='red', linestyle='--') # 전체 평균 지연율\n",
                "plt.show()\n",
                "\n",
                "# 4. 수치형 변수의 구간별 지연율 (Weight_in_gms vs 지연율)\n",
                "# 무게(Weight)는 특정 구간에서 지연이 몰릴 수 있으므로 qcut으로 나누어 봅니다.\n",
                "df['Weight_bin'] = pd.qcut(df['Weight_in_gms'], 5)\n",
                "plt.figure(figsize=(10, 5))\n",
                "sns.barplot(x='Weight_bin', y='Reached.on.Time_Y.N', data=df)\n",
                "plt.xticks(rotation=45)\n",
                "plt.title(\"Delay Rate by Weight Bins\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from xgboost import XGBClassifier\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "# 1. 데이터 로드\n",
                "df = pd.read_csv('data/Train.csv')\n",
                "df.columns = df.columns.str.strip()\n",
                "\n",
                "# 2. 피처 엔지니어링 (배송 전 확실히 알 수 있는 정보만 사용)\n",
                "df['Is_High_Discount'] = (df['Discount_offered'] > 10).astype(int)\n",
                "df['Weight_Type'] = pd.cut(df['Weight_in_gms'], \n",
                "                           bins=[0, 2000, 4000, 6000, 10000], \n",
                "                           labels=[0, 1, 2, 3]).astype(int)\n",
                "df['Cost_per_Weight'] = df['Cost_of_the_Product'] / (df['Weight_in_gms'] + 1)\n",
                "\n",
                "# 3. 범주형 변수 인코딩\n",
                "le = LabelEncoder()\n",
                "for col in ['Warehouse_block', 'Mode_of_Shipment', 'Product_importance', 'Gender']:\n",
                "    df[col] = le.fit_transform(df[col].astype(str))\n",
                "\n",
                "# ---------------------------------------------------------\n",
                "# [핵심 변경] 예측 시점에서 알 수 없는 사후 데이터 제거\n",
                "# Customer_rating: 배송 완료 후 고객이 매기는 점수 (Leakage 위험)\n",
                "# Customer_care_calls: 지연 발생 후 항의 전화일 가능성 (Leakage 위험)\n",
                "# ---------------------------------------------------------\n",
                "drop_cols = ['ID', 'Reached.on.Time_Y.N', 'Customer_rating', 'Customer_care_calls']\n",
                "X = df.drop(drop_cols, axis=1)\n",
                "y = df['Reached.on.Time_Y.N']\n",
                "\n",
                "# 팀의 방식대로 분할 (stratify 적용)\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42, stratify=y\n",
                ")\n",
                "\n",
                "# 4. 모델 학습 (XGBoost 최적화 파라미터)\n",
                "final_model = XGBClassifier(\n",
                "    n_estimators=500,\n",
                "    learning_rate=0.01,\n",
                "    max_depth=5,\n",
                "    subsample=0.8,\n",
                "    colsample_bytree=0.8,\n",
                "    eval_metric='logloss',\n",
                "    random_state=42\n",
                ")\n",
                "\n",
                "final_model.fit(X_train, y_train)\n",
                "\n",
                "# 5. 결과 확인\n",
                "y_pred = final_model.predict(X_test)\n",
                "print(f\"사후 데이터 제외 후 최종 정확도: {accuracy_score(y_test, y_pred):.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# [6] 최종 결과 및 변수 중요도 시각화\n",
                "y_pred = final_model.predict(X_test)\n",
                "print(f\"최종 정확도: {accuracy_score(y_test, y_pred):.4f}\")\n",
                "\n",
                "# 어떤 컬럼이 가장 기여를 했는가?\n",
                "importances = pd.Series(final_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.barplot(x=importances, y=importances.index)\n",
                "plt.title(\"Final Feature Importance\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# 시각화를 위한 한글 설정 (환경에 따라 생략 가능)\n",
                "plt.rc('font', family='Malgun Gothic') \n",
                "plt.rcParams['axes.unicode_minus'] = False\n",
                "\n",
                "# 1. 시각화 영역 설정 (2개의 그래프를 가로로 배치)\n",
                "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
                "\n",
                "# 2. 창고 구역별 지연율 시각화\n",
                "# Reached.on.Time_Y.N의 평균값은 곧 지연율(0~1 사이)을 의미합니다.\n",
                "sns.barplot(x='Warehouse_block', y='Reached.on.Time_Y.N', data=df, ax=ax[0], palette='Blues_d')\n",
                "ax[0].set_title('창고 구역별 지연율', fontsize=15)\n",
                "ax[0].set_ylabel('지연율 (0.6 = 60%)')\n",
                "ax[0].axhline(df['Reached.on.Time_Y.N'].mean(), color='red', linestyle='--', label='전체 평균')\n",
                "ax[0].legend()\n",
                "\n",
                "# 3. 배송 방식별 지연율 시각화\n",
                "sns.barplot(x='Mode_of_Shipment', y='Reached.on.Time_Y.N', data=df, ax=ax[1], palette='Greens_d')\n",
                "ax[1].set_title('배송 방식별 지연율', fontsize=15)\n",
                "ax[1].set_ylabel('지연율 (0.6 = 60%)')\n",
                "ax[1].axhline(df['Reached.on.Time_Y.N'].mean(), color='red', linestyle='--', label='전체 평균')\n",
                "ax[1].legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# 실제 수치로 확인\n",
                "print(\"--- 창고별 지연율 수치 ---\")\n",
                "print(df.groupby('Warehouse_block')['Reached.on.Time_Y.N'].mean().sort_values(ascending=False))\n",
                "print(\"\\n--- 배송 방식별 지연율 수치 ---\")\n",
                "print(df.groupby('Mode_of_Shipment')['Reached.on.Time_Y.N'].mean().sort_values(ascending=False))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# 시각화 영역 설정\n",
                "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
                "\n",
                "# 1. 이전 구매 내역(Prior_purchases)별 지연율\n",
                "# 구매 경험이 많은 '단골'일수록 배송 패턴이 다를까?\n",
                "sns.barplot(x='Prior_purchases', y='Reached.on.Time_Y.N', data=df, ax=ax[0], palette='magma', ci=None)\n",
                "ax[0].set_title('이전 구매 횟수별 지연율', fontsize=15)\n",
                "ax[0].axhline(df['Reached.on.Time_Y.N'].mean(), color='red', linestyle='--', label='전체 평균')\n",
                "ax[0].legend()\n",
                "\n",
                "# 2. 제품 가격(Cost_of_the_Product)별 지연 분포\n",
                "# 가격이 비싸다고 더 빨리 올까? (KDE Plot으로 분포 확인)\n",
                "sns.kdeplot(data=df, x='Cost_of_the_Product', hue='Reached.on.Time_Y.N', fill=True, ax=ax[1])\n",
                "ax[1].set_title('제품 가격에 따른 지연/정시 분포', fontsize=15)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# 수치 데이터 확인\n",
                "print(\"--- 이전 구매 횟수별 지연율 ---\")\n",
                "print(df.groupby('Prior_purchases')['Reached.on.Time_Y.N'].mean())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from xgboost import XGBClassifier\n",
                "from lightgbm import LGBMClassifier\n",
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "# 1. 비교할 모델 리스트 생성\n",
                "models = {\n",
                "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
                "    'Random Forest': RandomForestClassifier(n_estimators=300, max_depth=10, random_state=42),\n",
                "    'XGBoost': XGBClassifier(n_estimators=500, learning_rate=0.01, max_depth=5, random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
                "    'LightGBM': LGBMClassifier(n_estimators=500, learning_rate=0.01, max_depth=5, random_state=42)\n",
                "}\n",
                "\n",
                "# 2. 모델 학습 및 정확도 저장\n",
                "results = []\n",
                "for name, model in models.items():\n",
                "    model.fit(X_train, y_train)          # 학습\n",
                "    pred = model.predict(X_test)         # 예측\n",
                "    acc = accuracy_score(y_test, pred)   # 정확도 계산\n",
                "    results.append({'Model': name, 'Accuracy': acc})\n",
                "\n",
                "# 3. 결과 데이터프레임 만들기\n",
                "df_results = pd.DataFrame(results).sort_values(by='Accuracy', ascending=False)\n",
                "\n",
                "# 4. 시각화 (모델별 성능 비교 막대 그래프)\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.barplot(x='Accuracy', y='Model', data=df_results, palette='viridis')\n",
                "plt.title('Model Accuracy Comparison', fontsize=15)\n",
                "plt.xlim(0.6, 0.7)  # 차이를 명확히 보기 위해 범위를 0.6~0.7로 설정\n",
                "for i, v in enumerate(df_results['Accuracy']):\n",
                "    plt.text(v, i, f\" {v:.4f}\", va='center', fontweight='bold')\n",
                "plt.show()\n",
                "\n",
                "print(df_results)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import confusion_matrix\n",
                "import seaborn as sns\n",
                "\n",
                "# 혼동 행렬 생성\n",
                "cm = confusion_matrix(y_test, y_pred)\n",
                "\n",
                "# 시각화\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
                "plt.title('Confusion Matrix: Prediction vs Reality')\n",
                "plt.xlabel('Predicted (0: On Time, 1: Delayed)')\n",
                "plt.ylabel('Actual (0: On Time, 1: Delayed)')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# 모델에서 중요도 추출\n",
                "importances = final_model.feature_importances_\n",
                "feature_names = X.columns\n",
                "\n",
                "# 데이터프레임으로 변환 및 정렬\n",
                "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
                "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
                "\n",
                "# 시각화\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.barplot(x='Importance', y='Feature', data=feature_importance_df, palette='magma')\n",
                "plt.title('Feature Importance: What drives Delivery Delay?', fontsize=15)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. 모델 선언 시 eval_metric을 미리 설정합니다.\n",
                "final_model = XGBClassifier(\n",
                "    n_estimators=500,\n",
                "    learning_rate=0.01,\n",
                "    max_depth=5,\n",
                "    random_state=42,\n",
                "    eval_metric='logloss'  # 여기서 설정\n",
                ")\n",
                "\n",
                "# 2. fit 단계에서는 eval_metric을 뺍니다.\n",
                "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
                "final_model.fit(X_train, y_train, eval_set=eval_set, verbose=False)\n",
                "\n",
                "# 3. 결과 추출 및 시각화 (이전과 동일)\n",
                "results = final_model.evals_result()\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.plot(results['validation_0']['logloss'], label='Train Loss')\n",
                "plt.plot(results['validation_1']['logloss'], label='Test Loss')\n",
                "plt.title('XGBoost Learning Curve')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 학습 데이터 점수 확인\n",
                "train_pred = final_model.predict(X_train)\n",
                "print(f\"Train Accuracy: {accuracy_score(y_train, train_pred):.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. 학습 데이터 정확도\n",
                "train_acc = accuracy_score(y_train, final_model.predict(X_train))\n",
                "\n",
                "# 2. 테스트 데이터 정확도 (우리가 얻은 0.71)\n",
                "test_acc = accuracy_score(y_test, final_model.predict(X_test))\n",
                "\n",
                "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
                "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
                "print(f\"차이: {abs(train_acc - test_acc):.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. 모든 테스트 데이터에 대해 지연될 확률(predict_proba) 계산\n",
                "# [:, 1]은 '지연(1)'이 될 확률을 의미합니다.\n",
                "probabilities = final_model.predict_proba(X_test)[:, 1]\n",
                "\n",
                "# 2. 결과를 보기 쉽게 데이터프레임으로 정리\n",
                "risk_list = pd.DataFrame({\n",
                "    'Actual_Status': y_test.values,          # 실제 지연 여부 (확인용)\n",
                "    'Delay_Probability': probabilities,      # 모델이 예측한 지연 확률\n",
                "})\n",
                "\n",
                "# 원본 데이터의 특징들을 다시 합쳐서 어떤 조건인지 확인\n",
                "risk_list = pd.concat([risk_list, X_test.reset_index(drop=True)], axis=1)\n",
                "\n",
                "# 3. 확률이 높은 순서대로 10명 추출\n",
                "top_10_high_risk = risk_list.sort_values(by='Delay_Probability', ascending=False).head(10)\n",
                "\n",
                "# 주요 컬럼만 출력 (확률, 할인율, 무게, 파생변수 등)\n",
                "print(top_10_high_risk[['Delay_Probability', 'Discount_offered', 'Is_High_Discount', 'Weight_in_gms', 'Cost_of_the_Product']])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from xgboost import XGBClassifier\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "# 1. 데이터 로드\n",
                "df = pd.read_csv('data/Train.csv')\n",
                "\n",
                "# 2. [사용자님 전략] 할인율 파생 변수 생성\n",
                "df['Is_High_Discount'] = (df['Discount_offered'] > 10).astype(int)\n",
                "\n",
                "# 3. [팀원분 전략] 무게 데이터 전처리\n",
                "# (1) 로그 변환: 데이터의 비대칭성 해소\n",
                "df['Weight_log'] = np.log1p(df['Weight_in_gms'])\n",
                "\n",
                "# (2) 3단계 레이블링 (Light, Medium, Heavy)\n",
                "# 데이터 분포를 고려하여 2000g 미만(0), 2000~4000g(1), 4000g 초과(2)로 분류\n",
                "df['Weight_Level'] = pd.cut(df['Weight_in_gms'], \n",
                "                            bins=[0, 2000, 4000, 10000], \n",
                "                            labels=[0, 1, 2]).astype(int)\n",
                "\n",
                "# 4. 범주형 변수 인코딩\n",
                "le = LabelEncoder()\n",
                "for col in ['Warehouse_block', 'Mode_of_Shipment', 'Product_importance', 'Gender']:\n",
                "    df[col] = le.fit_transform(df[col].astype(str))\n",
                "\n",
                "# 5. 데이터 분할 (불필요한 원본 무게 컬럼 등은 제외하거나 포함해서 학습)\n",
                "X = df.drop(['ID', 'Reached.on.Time_Y.N'], axis=1)\n",
                "y = df['Reached.on.Time_Y.N']\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "# 6. 최종 모델 설정 (XGBoost)\n",
                "final_model = XGBClassifier(\n",
                "    n_estimators=500,\n",
                "    learning_rate=0.01,\n",
                "    max_depth=5,\n",
                "    subsample=0.8,\n",
                "    colsample_bytree=0.8,\n",
                "    random_state=42,\n",
                "    eval_metric='logloss'\n",
                ")\n",
                "\n",
                "final_model.fit(X_train, y_train)\n",
                "\n",
                "# 7. 결과 확인\n",
                "train_acc = accuracy_score(y_train, final_model.predict(X_train))\n",
                "test_acc = accuracy_score(y_test, final_model.predict(X_test))\n",
                "\n",
                "print(f\"최종 Train 정확도: {train_acc:.4f}\")\n",
                "print(f\"최종 Test 정확도: {test_acc:.4f}\")\n",
                "print(f\"두 점수 차이: {abs(train_acc - test_acc):.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# 모델에서 중요도 추출\n",
                "importances = final_model.feature_importances_\n",
                "feature_names = X.columns\n",
                "\n",
                "# 데이터프레임으로 변환 및 정렬\n",
                "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
                "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
                "\n",
                "# 시각화\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.barplot(x='Importance', y='Feature', data=feature_importance_df, palette='magma')\n",
                "plt.title('Feature Importance: What drives Delivery Delay?', fontsize=15)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# 변수 중요도 시각화\n",
                "importances = pd.Series(final_model.feature_importances_, index=X.columns)\n",
                "importances.sort_values().plot(kind='barh', figsize=(10, 6), color='skyblue')\n",
                "plt.title('Feature Importances (Including Prior Purchases)')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from xgboost import XGBClassifier\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.metrics import accuracy_score, classification_report\n",
                "\n",
                "# 1. 데이터 로드\n",
                "df = pd.read_csv('data/Train.csv')\n",
                "\n",
                "# 2. [사용자님 전략] 할인율 10% 기준 파생 변수\n",
                "df['Is_High_Discount'] = (df['Discount_offered'] > 10).astype(int)\n",
                "\n",
                "# 3. [팀원분 전략 A] 무게 데이터 전처리 (로그 변환 + 3단계 레이블링)\n",
                "df['Weight_log'] = np.log1p(df['Weight_in_gms'])\n",
                "df['Weight_Level'] = pd.cut(df['Weight_in_gms'], \n",
                "                            bins=[0, 2000, 4000, 10000], \n",
                "                            labels=[0, 1, 2]).astype(int)\n",
                "\n",
                "# 4. [팀원분 전략 B] 이전 구매 횟수 그룹화 (6회 이상 통합)\n",
                "# 표본이 적은 6, 7, 8, 10회를 하나로 묶어 '충성 고객군'의 특징을 강화합니다.\n",
                "df['Prior_Group'] = df['Prior_purchases'].apply(lambda x: x if x < 6 else 6)\n",
                "\n",
                "# 5. 범주형 변수 인코딩\n",
                "le = LabelEncoder()\n",
                "categorical_cols = ['Warehouse_block', 'Mode_of_Shipment', 'Product_importance', 'Gender']\n",
                "for col in categorical_cols:\n",
                "    df[col] = le.fit_transform(df[col].astype(str))\n",
                "\n",
                "# 6. 학습 데이터 준비\n",
                "# 원본 데이터와 가공 데이터 중 모델이 가장 잘 학습하는 조합으로 구성\n",
                "features = [\n",
                "    'Warehouse_block', 'Mode_of_Shipment', 'Customer_care_calls', 'Customer_rating',\n",
                "    'Cost_of_the_Product', 'Prior_Group', 'Product_importance', 'Gender',\n",
                "    'Discount_offered', 'Is_High_Discount', 'Weight_log', 'Weight_Level'\n",
                "]\n",
                "\n",
                "X = df[features]\n",
                "y = df['Reached.on.Time_Y.N']\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "# 7. 최종 하이퍼파라미터 튜닝 모델\n",
                "final_model = XGBClassifier(\n",
                "    n_estimators=100,\n",
                "    learning_rate=0.03,\n",
                "    max_depth=5,\n",
                "    min_child_weight=1,\n",
                "    gamma=0.2,\n",
                "    subsample=0.8,\n",
                "    colsample_bytree=0.8,\n",
                "    random_state=42,\n",
                "    eval_metric='logloss'\n",
                ")\n",
                "\n",
                "final_model.fit(X_train, y_train)\n",
                "\n",
                "# 8. 결과 출력\n",
                "train_pred = final_model.predict(X_train)\n",
                "test_pred = final_model.predict(X_test)\n",
                "\n",
                "print(f\"최종 Train 정확도: {accuracy_score(y_train, train_pred):.4f}\")\n",
                "print(f\"최종 Test 정확도: {accuracy_score(y_test, test_pred):.4f}\")\n",
                "print(\"-\" * 30)\n",
                "print(\"클래스별 상세 진단 (Test 데이터 기준):\")\n",
                "print(classification_report(y_test, test_pred))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import confusion_matrix\n",
                "import seaborn as sns\n",
                "\n",
                "cm = confusion_matrix(y_test, y_pred)\n",
                "plt.figure(figsize=(7, 5))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
                "plt.title('Confusion Matrix: Prediction vs Reality')\n",
                "plt.xlabel('Predicted')\n",
                "plt.ylabel('Actual')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 창고별 할인율 10% 초과 물량의 지연 현황 (이미 100%겠지만, 창고별 물량 비중 확인)\n",
                "df[df['Discount_offered'] > 10].groupby('Warehouse_block').size()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# 할인율 구간별 평균 무게 확인\n",
                "sns.boxplot(x='Is_High_Discount', y='Weight_in_gms', data=df)\n",
                "plt.title('Weight Distribution by High Discount')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# 1. 데이터 로드\n",
                "df = pd.read_csv('data/Train.csv')\n",
                "\n",
                "# 2. 상관계수 분석용 데이터 준비 (범주형은 숫자로 변환)\n",
                "df_corr = df.copy()\n",
                "for col in ['Warehouse_block', 'Mode_of_Shipment', 'Product_importance', 'Gender']:\n",
                "    df_corr[col] = pd.factorize(df_corr[col])[0]\n",
                "\n",
                "# 3. 상관관계 히트맵 (Heatmap)\n",
                "plt.figure(figsize=(12, 8))\n",
                "# Reached.on.Time_Y.N과의 상관관계 위주로 보기 위해 정렬할 수 있습니다.\n",
                "corr_matrix = df_corr.corr()\n",
                "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='RdYlGn', center=0)\n",
                "plt.title('Feature Correlation Heatmap')\n",
                "plt.show()\n",
                "\n",
                "# 4. [핵심 분석] 할인율 10% 기준 지연율 시각화\n",
                "df['Discount_Group'] = df['Discount_offered'].apply(lambda x: 'Over 10%' if x > 10 else '10% or Less')\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.countplot(x='Discount_Group', hue='Reached.on.Time_Y.N', data=df)\n",
                "plt.title('Delivery Delay by Discount Group (10% Threshold)')\n",
                "plt.ylabel('Number of Orders')\n",
                "plt.show()\n",
                "\n",
                "# 5. 할인율과 무게의 관계 (병목 현상 추론)\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.boxplot(x='Discount_Group', y='Weight_in_gms', data=df)\n",
                "plt.title('Weight Distribution: High vs Low Discount')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 제품 중요도와 할인 그룹 간의 교차 분석\n",
                "pivot_table = df.pivot_table(index='Product_importance', \n",
                "                             columns='Discount_Group', \n",
                "                             values='Reached.on.Time_Y.N', \n",
                "                             aggfunc='mean')\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.heatmap(pivot_table, annot=True, cmap='YlGnBu')\n",
                "plt.title('Delay Rate: Product Importance vs Discount Group')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from xgboost import XGBClassifier\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "# 1. 데이터 로드\n",
                "df = pd.read_csv('data/Train.csv')\n",
                "\n",
                "# 2. 파생 변수 생성\n",
                "# [기존 전략] 할인율 & 무게 & 구매횟수\n",
                "df['Is_High_Discount'] = (df['Discount_offered'] > 10).astype(int)\n",
                "df['Weight_log'] = np.log1p(df['Weight_in_gms'])\n",
                "df['Prior_Group'] = df['Prior_purchases'].apply(lambda x: x if x < 6 else 6)\n",
                "\n",
                "# [새로운 전략] 창고(Warehouse) + 배송수단(Shipment) 조합\n",
                "# 예: 'A_Flight', 'B_Ship' 등의 새로운 경로 변수 생성\n",
                "df['Route'] = df['Warehouse_block'].astype(str) + '_' + df['Mode_of_Shipment'].astype(str)\n",
                "\n",
                "# 3. 범주형 변수 인코딩 (Route 추가)\n",
                "le = LabelEncoder()\n",
                "categorical_cols = ['Warehouse_block', 'Mode_of_Shipment', 'Product_importance', 'Gender', 'Route']\n",
                "for col in categorical_cols:\n",
                "    df[col] = le.fit_transform(df[col].astype(str))\n",
                "\n",
                "# 4. 학습 데이터 구성 (중요도 낮은 변수는 제외하거나 유지)\n",
                "features = [\n",
                "    'Route', 'Customer_care_calls', 'Customer_rating', 'Cost_of_the_Product', \n",
                "    'Prior_Group', 'Is_High_Discount', 'Weight_log'\n",
                "]\n",
                "X = df[features]\n",
                "y = df['Reached.on.Time_Y.N']\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "# 5. 모델 학습 (안정적인 n_estimators=100 설정)\n",
                "final_model = XGBClassifier(\n",
                "    n_estimators=100,\n",
                "    learning_rate=0.03,\n",
                "    max_depth=5,\n",
                "    subsample=0.8,\n",
                "    colsample_bytree=0.8,\n",
                "    random_state=42,\n",
                "    eval_metric='logloss'\n",
                ")\n",
                "\n",
                "final_model.fit(X_train, y_train)\n",
                "\n",
                "# 6. 결과 확인\n",
                "train_acc = accuracy_score(y_train, final_model.predict(X_train))\n",
                "test_acc = accuracy_score(y_test, final_model.predict(X_test))\n",
                "\n",
                "print(f\"최종 Train 정확도: {train_acc:.4f}\")\n",
                "print(f\"최종 Test 정확도: {test_acc:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from xgboost import XGBClassifier\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
                "\n",
                "# 1. 데이터 로드\n",
                "df = pd.read_csv('data/Train.csv')\n",
                "\n",
                "# 2. [Feature Engineering] 모든 인사이트 집약\n",
                "# (1) 할인율 전략: 10% 초과 여부 (지연의 핵심 트리거)\n",
                "df['Is_High_Discount'] = (df['Discount_offered'] > 10).astype(int)\n",
                "\n",
                "# (2) 무게 전략 (팀원): 로그 변환 + 3단계 레이블링\n",
                "df['Weight_log'] = np.log1p(df['Weight_in_gms'])\n",
                "df['Weight_Level'] = pd.cut(df['Weight_in_gms'], \n",
                "                            bins=[0, 2000, 4000, 10000], \n",
                "                            labels=[0, 1, 2]).astype(int)\n",
                "\n",
                "# (3) 구매 횟수 전략 (팀원): 6회 이상 충성 고객 그룹화 (노이즈 제거)\n",
                "df['Prior_Group'] = df['Prior_purchases'].apply(lambda x: x if x < 6 else 6)\n",
                "\n",
                "# (4) 경로 전략 (최종): 창고(Warehouse) + 배송수단(Shipment) 조합\n",
                "df['Route'] = df['Warehouse_block'].astype(str) + '_' + df['Mode_of_Shipment'].astype(str)\n",
                "\n",
                "# 3. 인코딩 및 학습 준비\n",
                "le = LabelEncoder()\n",
                "# 범주형 변수들을 숫자로 변환\n",
                "cat_cols = ['Warehouse_block', 'Mode_of_Shipment', 'Product_importance', 'Gender', 'Route']\n",
                "for col in cat_cols:\n",
                "    df[col] = le.fit_transform(df[col].astype(str))\n",
                "\n",
                "# 사용할 특징 선별 (중요도가 낮았던 변수는 제외하거나 유지 가능)\n",
                "features = [\n",
                "    'Route', 'Customer_care_calls', 'Customer_rating', 'Cost_of_the_Product', \n",
                "    'Prior_Group', 'Product_importance', 'Is_High_Discount', 'Weight_log', \n",
                "    'Discount_offered' # 모델이 상세 수치도 참고할 수 있게 유지\n",
                "]\n",
                "\n",
                "X = df[features]\n",
                "y = df['Reached.on.Time_Y.N']\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "# 4. 최종 모델 학습 (과적합 방지를 위해 n_estimators=100으로 최적화)\n",
                "final_model = XGBClassifier(\n",
                "    n_estimators=100,\n",
                "    learning_rate=0.05,\n",
                "    max_depth=4,\n",
                "    subsample=0.8,\n",
                "    colsample_bytree=0.8,\n",
                "    random_state=42,\n",
                "    eval_metric='logloss'\n",
                ")\n",
                "\n",
                "final_model.fit(X_train, y_train)\n",
                "\n",
                "# 5. 성능 평가 결과 출력\n",
                "train_acc = accuracy_score(y_train, final_model.predict(X_train))\n",
                "test_acc = accuracy_score(y_test, final_model.predict(X_test))\n",
                "\n",
                "print(f\"--- [최종 모델 성적] ---\")\n",
                "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
                "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
                "print(f\"격차: {abs(train_acc - test_acc):.4f}\")\n",
                "print(\"\\n--- [상세 진단 보고서] ---\")\n",
                "print(classification_report(y_test, final_model.predict(X_test)))\n",
                "\n",
                "# 6. [시각화 1] 변수 중요도 (Feature Importance)\n",
                "plt.figure(figsize=(10, 6))\n",
                "importances = pd.Series(final_model.feature_importances_, index=features)\n",
                "importances.sort_values().plot(kind='barh', color='teal')\n",
                "plt.title('Final Model: Feature Importance Top Items')\n",
                "plt.xlabel('Importance Score')\n",
                "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
                "plt.show()\n",
                "\n",
                "# 7. [시각화 2] 혼동 행렬 (Confusion Matrix)\n",
                "plt.figure(figsize=(8, 6))\n",
                "cm = confusion_matrix(y_test, final_model.predict(X_test))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
                "plt.title('Confusion Matrix: Predictive Performance')\n",
                "plt.xlabel('Predicted Label')\n",
                "plt.ylabel('True Label')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from xgboost import XGBClassifier\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from lightgbm import LGBMClassifier\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
                "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
                "\n",
                "# 1. 데이터 로드 및 전처리 (이전과 동일)\n",
                "df = pd.read_csv('data/Train.csv')\n",
                "df['Is_High_Discount'] = (df['Discount_offered'] > 10).astype(int)\n",
                "df['Weight_log'] = np.log1p(df['Weight_in_gms'])\n",
                "df['Prior_Group'] = df['Prior_purchases'].apply(lambda x: x if x < 6 else 6)\n",
                "df['Route'] = df['Warehouse_block'].astype(str) + '_' + df['Mode_of_Shipment'].astype(str)\n",
                "\n",
                "le = LabelEncoder()\n",
                "cat_cols = ['Warehouse_block', 'Mode_of_Shipment', 'Product_importance', 'Gender', 'Route']\n",
                "for col in cat_cols:\n",
                "    df[col] = le.fit_transform(df[col].astype(str))\n",
                "\n",
                "features = ['Route', 'Customer_care_calls', 'Customer_rating', 'Cost_of_the_Product', \n",
                "            'Prior_Group', 'Product_importance', 'Is_High_Discount', 'Weight_log', 'Discount_offered']\n",
                "X = df[features]\n",
                "y = df['Reached.on.Time_Y.N']\n",
                "\n",
                "# 수치형 변수 스케일링 (로지스틱 회귀를 위해 필요)\n",
                "scaler = StandardScaler()\n",
                "X_scaled = scaler.fit_transform(X)\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "# 2. 모델 리스트 정의\n",
                "models = {\n",
                "    \"Logistic Regression\": LogisticRegression(),\n",
                "    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42),\n",
                "    \"XGBoost\": XGBClassifier(n_estimators=100, learning_rate=0.05, max_depth=4, random_state=42, eval_metric='logloss'),\n",
                "    \"LightGBM\": LGBMClassifier(n_estimators=100, learning_rate=0.05, random_state=42)\n",
                "}\n",
                "\n",
                "# 3. 모델별 학습 및 평가\n",
                "results = []\n",
                "\n",
                "for name, model in models.items():\n",
                "    model.fit(X_train, y_train)\n",
                "    y_pred = model.predict(X_test)\n",
                "    \n",
                "    results.append({\n",
                "        \"Model\": name,\n",
                "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
                "        \"Precision\": precision_score(y_test, y_pred),\n",
                "        \"Recall\": recall_score(y_test, y_pred),\n",
                "        \"F1-Score\": f1_score(y_test, y_pred)\n",
                "    })\n",
                "\n",
                "# 4. 결과 테이블 출력\n",
                "result_df = pd.DataFrame(results)\n",
                "print(result_df.to_string(index=False))\n",
                "\n",
                "# 5. [시각화] 모델별 성능 비교\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.barplot(x='Accuracy', y='Model', data=result_df.sort_values(by='Accuracy', ascending=False), palette='viridis')\n",
                "plt.title('Model Accuracy Comparison')\n",
                "plt.xlim(0.6, 0.75) # 차이를 명확히 보기 위한 범위 설정\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from xgboost import XGBClassifier\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
                "\n",
                "# 1. 데이터 로드 및 전처리 (우리의 모든 전략 통합)\n",
                "df = pd.read_csv('data/Train.csv')\n",
                "\n",
                "# 피처 엔지니어링\n",
                "df['Is_High_Discount'] = (df['Discount_offered'] > 10).astype(int)\n",
                "df['Weight_log'] = np.log1p(df['Weight_in_gms'])\n",
                "df['Prior_Group'] = df['Prior_purchases'].apply(lambda x: x if x < 6 else 6)\n",
                "df['Route'] = df['Warehouse_block'].astype(str) + '_' + df['Mode_of_Shipment'].astype(str)\n",
                "\n",
                "# 인코딩\n",
                "le = LabelEncoder()\n",
                "for col in ['Warehouse_block', 'Mode_of_Shipment', 'Product_importance', 'Gender', 'Route']:\n",
                "    df[col] = le.fit_transform(df[col].astype(str))\n",
                "\n",
                "# 특성 선택\n",
                "features = ['Route', 'Customer_care_calls', 'Customer_rating', 'Cost_of_the_Product', \n",
                "            'Prior_Group', 'Product_importance', 'Is_High_Discount', 'Weight_log', 'Discount_offered']\n",
                "X = df[features]\n",
                "y = df['Reached.on.Time_Y.N']\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "# 2. 모델 학습 (XGBoost)\n",
                "final_model = XGBClassifier(\n",
                "    n_estimators=100,\n",
                "    learning_rate=0.05,\n",
                "    max_depth=4,\n",
                "    random_state=42,\n",
                "    eval_metric='logloss'\n",
                ")\n",
                "final_model.fit(X_train, y_train)\n",
                "\n",
                "# 3. 예측 및 확률 계산\n",
                "y_pred = final_model.predict(X_test)\n",
                "y_probs = final_model.predict_proba(X_test)[:, 1] # 지연(1)일 확률 추출\n",
                "\n",
                "# 4. 성능 지표 출력\n",
                "print(f\"--- [모델 성능 평가 보고서] ---\")\n",
                "print(f\"Accuracy : {accuracy_score(y_test, y_pred):.4f}\")\n",
                "print(f\"ROC-AUC  : {roc_auc_score(y_test, y_probs):.4f}\")\n",
                "print(\"\\n[상세 분류 보고서]\")\n",
                "print(classification_report(y_test, y_pred))\n",
                "\n",
                "# 5. [시각화] ROC 커브\n",
                "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
                "auc_val = roc_auc_score(y_test, y_probs)\n",
                "\n",
                "plt.figure(figsize=(12, 5))\n",
                "\n",
                "# 좌측: ROC 커브\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {auc_val:.2f})')\n",
                "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
                "plt.xlabel('False Positive Rate (실수율)')\n",
                "plt.ylabel('True Positive Rate (재현율)')\n",
                "plt.title('Receiver Operating Characteristic (ROC)')\n",
                "plt.legend(loc=\"lower right\")\n",
                "\n",
                "# 우측: 혼동 행렬\n",
                "plt.subplot(1, 2, 2)\n",
                "cm = confusion_matrix(y_test, y_pred)\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
                "plt.title('Confusion Matrix')\n",
                "plt.xlabel('Predicted')\n",
                "plt.ylabel('Actual')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from xgboost import XGBClassifier\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
                "from sklearn.calibration import calibration_curve\n",
                "\n",
                "# 1. 데이터 로드 및 전처리 (이전과 동일)\n",
                "df = pd.read_csv('data/Train.csv')\n",
                "df['Is_High_Discount'] = (df['Discount_offered'] > 10).astype(int)\n",
                "df['Weight_log'] = np.log1p(df['Weight_in_gms'])\n",
                "df['Route'] = df['Warehouse_block'].astype(str) + '_' + df['Mode_of_Shipment'].astype(str)\n",
                "\n",
                "le = LabelEncoder()\n",
                "for col in ['Warehouse_block', 'Mode_of_Shipment', 'Product_importance', 'Gender', 'Route']:\n",
                "    df[col] = le.fit_transform(df[col].astype(str))\n",
                "\n",
                "X = df[['Route', 'Customer_care_calls', 'Customer_rating', 'Cost_of_the_Product', \n",
                "        'Prior_purchases', 'Product_importance', 'Is_High_Discount', 'Weight_log']]\n",
                "y = df['Reached.on.Time_Y.N']\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "# 2. 모델 학습\n",
                "model = XGBClassifier(n_estimators=100, learning_rate=0.05, max_depth=4, random_state=42)\n",
                "model.fit(X_train, y_train)\n",
                "y_probs = model.predict_proba(X_test)[:, 1]\n",
                "\n",
                "# 3. 시각화 (PR 커브 & Calibration 커브)\n",
                "plt.figure(figsize=(15, 6))\n",
                "\n",
                "# [좌측] PR 커브: 모델이 지연(1)을 얼마나 정확하게 잡아내는가?\n",
                "plt.subplot(1, 2, 1)\n",
                "precision, recall, _ = precision_recall_curve(y_test, y_probs)\n",
                "ap_score = average_precision_score(y_test, y_probs)\n",
                "plt.plot(recall, precision, color='teal', lw=2, label=f'AP (Average Precision) = {ap_score:.2f}')\n",
                "plt.xlabel('Recall (재현율)')\n",
                "plt.ylabel('Precision (정밀도)')\n",
                "plt.title('Precision-Recall Curve')\n",
                "plt.legend()\n",
                "plt.grid(alpha=0.3)\n",
                "\n",
                "# [우측] Calibration 커브: 모델이 내뱉은 확률이 실제 확률과 일치하는가?\n",
                "plt.subplot(1, 2, 2)\n",
                "prob_true, prob_pred = calibration_curve(y_test, y_probs, n_bins=10)\n",
                "plt.plot(prob_pred, prob_true, marker='o', linewidth=1, label='XGBoost', color='darkorange')\n",
                "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfectly Calibrated')\n",
                "plt.xlabel('Mean Predicted Probability (예측 확률)')\n",
                "plt.ylabel('Fraction of Positives (실제 발생 확률)')\n",
                "plt.title('Calibration Curve (Reliability Diagram)')\n",
                "plt.legend()\n",
                "plt.grid(alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. 모델이 실제로 학습할 때 사용한 컬럼 이름을 가져옵니다.\n",
                "model_features = final_model.get_booster().feature_names\n",
                "\n",
                "# 2. 현재 X_test에 없는 컬럼이 있다면, 0이나 기본값으로라도 채워줍니다.\n",
                "# (XGBoost의 feature mismatch를 해결하는 가장 확실한 방법입니다)\n",
                "for col in model_features:\n",
                "    if col not in X_test.columns:\n",
                "        # Prior_Group이 없고 Prior_purchases가 있다면 계산해서 넣어줌\n",
                "        if col == 'Prior_Group' and 'Prior_purchases' in X_test.columns:\n",
                "            X_test['Prior_Group'] = X_test['Prior_purchases'].apply(lambda x: x if x < 6 else 6)\n",
                "        # Discount_offered가 사라졌다면 0으로라도 임시 생성 (에러 방지)\n",
                "        else:\n",
                "            X_test[col] = 0 \n",
                "            print(f\"경고: {col} 컬럼이 없어서 0으로 채웠습니다. 전처리 단계를 다시 확인해보세요!\")\n",
                "\n",
                "# 3. 모델이 배운 '순서' 그대로 다시 정렬\n",
                "X_test_final = X_test[model_features]\n",
                "\n",
                "# 4. ROC-AUC 계산 및 출력\n",
                "from sklearn.metrics import roc_auc_score, roc_curve\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "y_probs = final_model.predict_proba(X_test_final)[:, 1]\n",
                "auc_score = roc_auc_score(y_test, y_probs)\n",
                "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
                "\n",
                "plt.figure(figsize=(6, 5))\n",
                "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Curve (AUC = {auc_score:.2f})')\n",
                "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
                "plt.title('Final ROC Curve')\n",
                "plt.xlabel('False Positive Rate')\n",
                "plt.ylabel('True Positive Rate')\n",
                "plt.legend()\n",
                "plt.show()\n",
                "\n",
                "print(f\"성공! ROC-AUC 점수: {auc_score:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from xgboost import XGBClassifier\n",
                "from lightgbm import LGBMClassifier\n",
                "from sklearn.ensemble import VotingClassifier\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
                "\n",
                "# 1. 데이터 로드\n",
                "df = pd.read_csv('data/Train.csv')\n",
                "\n",
                "# 2. 파생변수 생성 (Feature Engineering)\n",
                "# 할인율 10% 초과 여부 (지연의 핵심 트리거)\n",
                "df['Is_High_Discount'] = (df['Discount_offered'] > 10).astype(int)\n",
                "# 무게 로그 변환 (치우친 데이터 완화)\n",
                "df['Weight_log'] = np.log1p(df['Weight_in_gms'])\n",
                "# 배송 경로 조합 (창고 x 배송수단)\n",
                "df['Route'] = df['Warehouse_block'].astype(str) + '_' + df['Mode_of_Shipment'].astype(str)\n",
                "\n",
                "# 3. 인코딩 (범주형 -> 수치형)\n",
                "le = LabelEncoder()\n",
                "categorical_cols = ['Warehouse_block', 'Mode_of_Shipment', 'Product_importance', 'Gender', 'Route']\n",
                "for col in categorical_cols:\n",
                "    df[col] = le.fit_transform(df[col].astype(str))\n",
                "\n",
                "# 4. 학습 데이터 준비\n",
                "# 중요도와 상관관계가 높은 변수들 위주로 구성\n",
                "features = ['Route', 'Customer_care_calls', 'Customer_rating', 'Cost_of_the_Product', \n",
                "            'Prior_purchases', 'Product_importance', 'Is_High_Discount', 'Weight_log', 'Discount_offered']\n",
                "X = df[features]\n",
                "y = df['Reached.on.Time_Y.N']\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "# 5. 앙상블 모델 구축 (XGBoost + LightGBM)\n",
                "xgb = XGBClassifier(n_estimators=100, learning_rate=0.05, max_depth=5, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
                "lgbm = LGBMClassifier(n_estimators=100, learning_rate=0.05, max_depth=5, random_state=42)\n",
                "\n",
                "ensemble = VotingClassifier(\n",
                "    estimators=[('xgb', xgb), ('lgbm', lgbm)],\n",
                "    voting='soft' # 확률 기반 평균\n",
                ")\n",
                "\n",
                "# 6. 모델 학습 및 예측\n",
                "ensemble.fit(X_train, y_train)\n",
                "y_probs = ensemble.predict_proba(X_test)[:, 1]\n",
                "y_pred = ensemble.predict(X_test)\n",
                "\n",
                "# 7. 결과 출력 및 시각화\n",
                "auc_score = roc_auc_score(y_test, y_probs)\n",
                "acc_score = accuracy_score(y_test, y_pred)\n",
                "\n",
                "print(f\"=== 최종 모델 성능 ===\")\n",
                "print(f\"Accuracy : {acc_score:.4f}\")\n",
                "print(f\"ROC-AUC  : {auc_score:.4f}\")\n",
                "\n",
                "# ROC 커브 시각화\n",
                "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "plt.plot(fpr, tpr, color='red', lw=2, label=f'Ensemble ROC (AUC = {auc_score:.4f})')\n",
                "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
                "plt.xlabel('False Positive Rate (실수율)')\n",
                "plt.ylabel('True Positive Rate (정답률)')\n",
                "plt.title('Final Model ROC Curve (XGB + LGBM)')\n",
                "plt.legend(loc=\"lower right\")\n",
                "plt.grid(alpha=0.2)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.metrics import roc_auc_score, roc_curve\n",
                "\n",
                "# 사용할 모델들 임포트\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from xgboost import XGBClassifier\n",
                "from lightgbm import LGBMClassifier\n",
                "from catboost import CatBoostClassifier\n",
                "\n",
                "# 1. 데이터 로드 및 전처리 (이전과 동일)\n",
                "df = pd.read_csv('data/Train.csv')\n",
                "df['Is_High_Discount'] = (df['Discount_offered'] > 10).astype(int)\n",
                "df['Weight_log'] = np.log1p(df['Weight_in_gms'])\n",
                "\n",
                "le = LabelEncoder()\n",
                "for col in ['Warehouse_block', 'Mode_of_Shipment', 'Product_importance', 'Gender']:\n",
                "    df[col] = le.fit_transform(df[col].astype(str))\n",
                "\n",
                "features = ['Warehouse_block', 'Mode_of_Shipment', 'Customer_care_calls', 'Customer_rating', \n",
                "            'Cost_of_the_Product', 'Prior_purchases', 'Product_importance', \n",
                "            'Is_High_Discount', 'Weight_log', 'Discount_offered']\n",
                "X = df[features]\n",
                "y = df['Reached.on.Time_Y.N']\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "# 2. 비교할 모델 리스트 정의\n",
                "models = [\n",
                "    ('Logistic Regression', LogisticRegression(max_iter=1000)),\n",
                "    ('Random Forest', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
                "    ('XGBoost', XGBClassifier(n_estimators=100, learning_rate=0.05, use_label_encoder=False, eval_metric='logloss')),\n",
                "    ('LightGBM', LGBMClassifier(n_estimators=100, learning_rate=0.05)),\n",
                "    ('CatBoost', CatBoostClassifier(iterations=100, learning_rate=0.05, verbose=0))\n",
                "]\n",
                "\n",
                "# 3. 모델별 학습 및 평가\n",
                "results = []\n",
                "plt.figure(figsize=(10, 8))\n",
                "\n",
                "for name, model in models:\n",
                "    # 모델 학습\n",
                "    model.fit(X_train, y_train)\n",
                "    \n",
                "    # 예측 확률값 추출\n",
                "    y_probs = model.predict_proba(X_test)[:, 1]\n",
                "    \n",
                "    # AUC 계산\n",
                "    auc = roc_auc_score(y_test, y_probs)\n",
                "    results.append((name, auc))\n",
                "    \n",
                "    # ROC 커브 시각화 데이터 준비\n",
                "    fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
                "    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.4f})')\n",
                "\n",
                "# 4. 결과 출력 및 시각화\n",
                "results_df = pd.DataFrame(results, columns=['Model', 'ROC-AUC']).sort_values(by='ROC-AUC', ascending=False)\n",
                "print(\"\\n=== 모델별 성능 순위 ===\")\n",
                "print(results_df)\n",
                "\n",
                "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
                "plt.xlabel('False Positive Rate')\n",
                "plt.ylabel('True Positive Rate')\n",
                "plt.title('Comparison of Classification Models (ROC Curve)')\n",
                "plt.legend(loc=\"lower right\")\n",
                "plt.grid(alpha=0.3)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from catboost import CatBoostClassifier\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.metrics import roc_auc_score, roc_curve\n",
                "from imblearn.over_sampling import SMOTE # 데이터 불균형 해소 도구\n",
                "\n",
                "# 1. 데이터 로드 및 전처리\n",
                "df = pd.read_csv('data/Train.csv')\n",
                "df['Is_High_Discount'] = (df['Discount_offered'] > 10).astype(int)\n",
                "df['Weight_log'] = np.log1p(df['Weight_in_gms'])\n",
                "df['Route'] = df['Warehouse_block'].astype(str) + '_' + df['Mode_of_Shipment'].astype(str)\n",
                "\n",
                "le = LabelEncoder()\n",
                "for col in ['Warehouse_block', 'Mode_of_Shipment', 'Product_importance', 'Gender', 'Route']:\n",
                "    df[col] = le.fit_transform(df[col].astype(str))\n",
                "\n",
                "features = ['Route', 'Customer_care_calls', 'Customer_rating', 'Cost_of_the_Product', \n",
                "            'Prior_purchases', 'Product_importance', 'Is_High_Discount', 'Weight_log', 'Discount_offered']\n",
                "X = df[features]\n",
                "y = df['Reached.on.Time_Y.N']\n",
                "\n",
                "# 2. 데이터 분할\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "# 3. SMOTE 적용 (데이터 불균형 해소)\n",
                "# 적은 쪽 데이터를 가상으로 만들어내서 5:5 비율로 맞춥니다.\n",
                "smote = SMOTE(random_state=42)\n",
                "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
                "\n",
                "print(f\"SMOTE 적용 전 학습 데이터 수: {len(X_train)}\")\n",
                "print(f\"SMOTE 적용 후 학습 데이터 수: {len(X_train_res)}\")\n",
                "\n",
                "# 4. CatBoost 모델 학습\n",
                "# CatBoost는 자체적으로 범주형 변수를 지정할 수 있지만, 여기서는 이미 인코딩된 데이터를 씁니다.\n",
                "cat_model = CatBoostClassifier(\n",
                "    iterations=500,\n",
                "    learning_rate=0.05,\n",
                "    depth=6,\n",
                "    eval_metric='AUC',\n",
                "    random_seed=42,\n",
                "    verbose=100 # 100회마다 학습 결과 출력\n",
                ")\n",
                "\n",
                "cat_model.fit(X_train_res, y_train_res, eval_set=(X_test, y_test))\n",
                "\n",
                "# 5. 결과 확인 및 시각화\n",
                "y_probs = cat_model.predict_proba(X_test)[:, 1]\n",
                "auc_score = roc_auc_score(y_test, y_probs)\n",
                "\n",
                "fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
                "plt.figure(figsize=(8, 6))\n",
                "plt.plot(fpr, tpr, color='purple', lw=2, label=f'CatBoost + SMOTE (AUC = {auc_score:.4f})')\n",
                "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
                "plt.title('Final CatBoost ROC Curve')\n",
                "plt.xlabel('False Positive Rate')\n",
                "plt.ylabel('True Positive Rate')\n",
                "plt.legend()\n",
                "plt.show()\n",
                "\n",
                "print(f\"최종 CatBoost ROC-AUC 점수: {auc_score:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
                "\n",
                "# 1. 모델 예측 (이미 모델 학습이 완료된 상태여야 합니다)\n",
                "y_pred = cat_model.predict(X_test)      # 0 또는 1로 예측\n",
                "y_probs = cat_model.predict_proba(X_test)[:, 1] # 확률값으로 예측\n",
                "\n",
                "# 2. 결과 출력\n",
                "print(\"--- [모델 성능 평가 보고서] ---\")\n",
                "print(f\"Accuracy : {accuracy_score(y_test, y_pred):.4f}\")\n",
                "print(f\"ROC-AUC  : {roc_auc_score(y_test, y_probs):.4f}\")\n",
                "print(\"\\n[상세 분류 보고서]\")\n",
                "print(classification_report(y_test, y_pred))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "DS",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
